<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Johnny Kantaros">
<meta name="dcterms.date" content="2023-04-19">
<meta name="description" content="Learning from Timnit Gebru.">

<title>Welcome to my blog! - Timnit Gebru</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>
    .quarto-title-block .quarto-title-banner {
      color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
    }
    </style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Welcome to my blog!</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/johnny-kantaros"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Timnit Gebru</h1>
                  <div>
        <div class="description">
          Learning from Timnit Gebru.
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Johnny Kantaros </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 19, 2023</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="part-1-questions-for-dr.-gebru" class="level1">
<h1>Part 1: Questions for Dr.&nbsp;Gebru</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>On Monday, April 24, Dr.&nbsp;Gebru is virtually visiting Middlebury to speak with both our class and the rest of campus.</p>
<p>Dr.&nbsp;Gebru is an accomplished Computer Scientist and researcher who is best known for her contributions to the field of ethical AI, bias, and fairness. After being raised in Ethiopia, she moved to the United States where she attended Stanford, completing both a Bachelor’s degree and Master’s degree in Electrical Engineering, and a PhD in Computer Vision. After completing her PhD, Gebru joined Microsoft where she worked as a postdoctoral researcher in the Fairness, Accountability, Transparency, and Ethics in AI (FATE) lab. This group focused on addressing the issues of bias and fairness present in algorithms and promoted responsible deployment. Gebru then joined Google in 2018, where she took a leadership position in analyzing algorithmic bias and ethics related to AI. In 2020, she was abruptly fired from Google following multiple papers which highlighted biases and ethical concerns in the tech industry, especially relating to her experience at Google. Her termination sparked widespread controversy and outrage, which shed light on the power dynamics in the industry. Since then, Dr.&nbsp;Gebru has worked independently, and she has recently launched a venture called, “Black in AI,” which will model her research performed at Google and attempt to shed even more light on bias and fairness in the tech industry.</p>
</section>
<section id="speech" class="level2">
<h2 class="anchored" data-anchor-id="speech">2020 Speech</h2>
<p>In her 2020 speech, Dr.&nbsp;Gebru analyzes bias and discrimination in computer vision. For much of her talk, she focuses on societal and ethical impacts of common computer vision applications, including facial recognition and gender classification.</p>
<p>As she states in the beginning of her speech, the area of bias and fairness in computer vision is very underrepresented by minority groups, which is problematic as computer vision applications has been proven to disproportionately harm these communities. She also speaks about commonly used datasets that are used to train computer vision models. More specifically, she makes a call for more data diversity in order to better represent marginalized groups. Because these datasets are often comprised of privileged individuals (white, male, etc), the resulting models are often disproportionately harmful to black and brown communities. For example, classification algorithms which predict an individual’s race and sex are much better at predicting white men than black women. Another example she made was car tests, which typically use white men to test the effectivity of the vehicle. Consequently, women and children are often the victims of car accident deaths in these cars. Finally, she mentions the fact that most clinical drug testing is performed on white people/men, and therefore most adverse reactions stem from minority groups.</p>
<p>Additionally, she discusses the applications of common computer vision applications. For example, she argues that AI can be bias in facial recognition. She brings up the application of Baltimore PD who used facial recognition for surveillance purposes. The result of this implementation ended up disproportionally hurting minorities in the Baltimore community and lead to the arrest of many black people. Additionally, facial recognition has a major impact on immigrants and is the cause of many immigrants being deported due to ICE violations.</p>
<p>Finally, she brings up the question of “why implement these algorithms in the first place.” I have never heard this argument before, and I think she makes a lot of valid points. For example, why do we need gender classification algorithms? A large application of this model is used for targeting advertising, but as she argues, this only reaffirms existing gender stereotypes. We as a society need to consider the “why” question when implementing algorithms and consider the ethical and societal impact the technology will have.</p>
</section>
<section id="proposed-question" class="level2">
<h2 class="anchored" data-anchor-id="proposed-question">Proposed question</h2>
<p>You spoke about the need for more diversity in common datasets, yet also mentioned the problem with taking photos and data from minorities without explicit consent. Even with consent, often times this data can be used for harm. What is the solution to this problem? That is, how do we find a balance between making sure minorities are represented in datasets while also respecting privacy?</p>
</section>
</section>
<section id="part-2---dr.-gebrus-talk-at-middlebury" class="level1">
<h1>Part 2 - Dr.&nbsp;Gebru’s Talk “At” Middlebury</h1>
<p>On Monday, Dr.&nbsp;Gebru virtually visited our class and gave a ~50 minute lecture, leaving time for questions at the end. She started off her time by discussing the recent rise in AGI (Artificial General Intelligence) and the origin of this field. More specifically, she noted that AGI’s central mission is to build a God-like model with exceptional intelligence. Unlike many ML models which we have examined in class, the purpose of AGI is to create a <em>general</em> intelligence, one that is both approachable and limitless in its capabilities.</p>
<p>For the next part of her lecture, Dr.&nbsp;Gebru discussed the history of eugenics and its connection to AI. As she noted, there have been multiple waves of eugenics throughout time. The first, and most notable, took place in the late 19th century and lasted until the early 20th century. This wave was popularized by British scientist Francis Galton (who was a cousin of Charles Darwin). Galton and other eugenicists believed in selective breeding in the human race to limit the spreading of “undesirable traits.”</p>
<p>Dr.&nbsp;Gebru argued that eugenics did not end after World War II. Instead, we saw a second wave spread in the second half of the 20th century. This time, not only was there a focus on negative eugenics (including sterilization), but we also saw an emergence of “positive eugenics.” With the rise of medical technology, certain procedures such as gene editing came into the scene. Since their conception in society, these procedures have been very contentious. The idea of creating “genetically superior” humans disturbed many individuals, and the accessibility of these procedures also raised the question of fairness and adverse effects. That is, who would be able to afford these procedures, and who would be left behind?</p>
<p>Finally, Dr.&nbsp;Gebru explained the most recent wave of eugenics, which she argued is taking place right now. This time, the rise of AGI is creating a scenario in which we may soon be able to transcend humanity all together. This concept is properly coined, “Transhumanism.” In this wave, humans will soon merge with technology. Transhumanists believe AGI can be used to enhance the human experience and even permit “an indefinite lifespan to those who choose to leave biology behind.” She described the point of “singularity,” in which the rate of technology has progressed so fast that it is unstoppable and smarter than humans. She anticipated that the singularity could be reached sooner rather than later, much to the dismay of many students in the room.</p>
<p>She ended her talk by raising the question: AGI Utopia - For Whom?</p>
<p>This was a very interesting segment in her lecture. When we typically think about AGI, we think about all the applications (ex. ChatGPT, biological enhancements, etc), but we forget to consider the relevant stakeholders. More specifically, who benefits from the rise of AGI, and who suffers?</p>
<p>Dr.&nbsp;Gebru believes the biggest beneficiary of AGI will be the companies who make it, such as Open AI and Google. She believes their is massive exploitation in the industry and brought up the example of Open AI hiring cheap labor from foreign countries to train the content moderation of ChatGPT. There have been accounts of severe mental health problems following these employments, and Open AI only paid $2/hour for these workers to read and react to horrible content all day long.</p>
<p>Finally, I want to mention the AGI Apocalypse Dr.&nbsp;Gebru mentioned towards the end of her speech. In her words, she believes AGI poses a massive risk of destroying any chance of “utopia” in society. She notes that while people are concerned about safety issues, there has been a gradual shift in accountability away from developers and instead towards the AGI itself. This is a dangerous trend, and she called for developers to remain accountable for their creations.</p>
<section id="my-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="my-thoughts">My thoughts</h3>
<p>I really enjoyed Dr.&nbsp;Gebru’s talk, and I believe she raised some important issues. First of all, I did not know about the rise of Transhumanism, and I was shocked to hear about the proposed applications and associated ideology. She was spot on with her discussion of the singularity, and I believe we have already seen this concept materialize in our society today. While we have not hit the true point of no return, we have seen how fast AGI is progressing, and how almost everyday it gets smarter. For example, only a few months after the widespread release of ChatGPT, we are seeing other companies release their own advanced AGI - Snapchat and Einstein (Salesforce) are two examples that have been very popular in the news recently. This race to the top is what Dr.&nbsp;Gebru fears, and the point of singularity may be sooner than we think.</p>
<p>I mostly agree in her analysis of “AGI Utopia - For Whom?” She is correct in her assessment that many people are harmed by the rise of AGI. More specifically, I thought her example of the content moderation process was particularly powerful. Furthermore, I think her connection to eugenics more or less worked. I do agree that AGI in the Transhumanist context will absolutely benefit certain groups more than others. However, I was not positive eugenics was the correct assessment of this movement. As someone asked in the Q&amp;A, couldn’t this just been seen as a “trickle down” instance in which new technology starts at the top of the societal pyramid and slowly makes its way down to those with lesser means? I agreed with this perspective a little more than the idea of eugenics when analyzing this phenomenon. Does that mean everyone will benefit equally? Absolutely not. I believe the idea of Transhumanism is very scary and needs strict regulation. I also believe we need more people like her working in the field to assess biases and fairness within AGI and technological advancements.</p>
<p>Finally, I have mixed opinions about her strong pessimism towards the future of AGI. I believe there are many positive applications of advanced technology being created. For example, I believe AGI will soon be used to cure many diseases and impairments, which will change the lives of many people. Like most technologies in society, there will be a large spectrum of its use. For example, just because the dark web exists does not mean the internet should be shut down entirely. While I do understand the scope and danger of AGI surpasses this example, I think we need to approach the topic with a similar mindset. I believe congress needs to implement strict legislation, and we as a society need to shift the accountability back towards the developers.</p>
</section>
</section>
<section id="part-3---closing-remarks" class="level1">
<h1>Part 3 - Closing remarks</h1>
<p>Dr.&nbsp;Gebru’s visit was very enlightening for me. Although I am familiar with ChatGPT and the idea of AGI, I had never learned the formal definition and origin story of the concept. I also learned a lot about ethical concerns in AGI, ranging from labor exploitation to privacy to ideas of eugenics. I found it empowering that there are people out there fighting for these concerns and inequalities. I am always fearful that not enough people go into this field, so it is re-encouraging to hear from a leader and learn about her work. As a result of this talk, I want to dig deeper into the positive aspects of AGI and see if they are worth fighting for. Coincidentally, I am about to start writing a research paper on Elon Musk’s Neuralink, which should be interesting after listening to this speech.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>