{"title":"Optimization with Gradient Descent","markdown":{"yaml":{"title":"Optimization with Gradient Descent","author":"Johnny Kantaros","date":"2023-03-04","image":"gradient.png","description":"Implementing Logistic Regression using Gradient Descent.","format":"html"},"headingText":"Logistic Regression using Gradient Descent","containsRefs":false,"markdown":"\n\n\n## Introduction: \n\nIn this blog post, I implement the Logistic Regression algorithm to linearly classify data. Unlike the Perceptron algorithm, which was implemented in blog post 1, the data does not have to be linearly separable for the LR algorithm to converge and provide an accurate weight vector, w, to separate our data.  \n  \nTo implement this algorithm, we rely on Gradient Descent to perform most of the heavy lifting. Gradient Descent is an optimization algorithm which can be performed to minimize convex Empirical Loss functions.  \n\nHere is the basic form of gradient descent:  \n\n$$\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1, ..., \\theta_n)$$\n\nwhere $\\theta_j$ is the $j^{th}$ parameter, $\\alpha$ is the learning rate, and $J(\\theta_0, \\theta_1, ..., \\theta_n)$ is the cost function. The partial derivative term $\\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1, ..., \\theta_n)$ represents the gradient of the cost function with respect to the $j^{th}$ parameter.\n\nIn the case of Logistic Regression, we will be seeking to minimize the Logistic Loss function, which has the form:  \n  \n$$-y\\log(\\sigma(\\hat{y})) - (1-y)\\log(1-\\sigma(\\hat{y}))$$\n\n## Implementation:  \n\n<a href=\"https://github.com/johnny-kantaros/gradient-descent/blob/main/LogisticRegression.py\">See Source Code</a>\n\nTo implement my fit() algorithm, I followed these steps:  \n\n1. Initialize w (weight vector) as random, X_ (padded input matrix)  \n2. While there were more possible iterations AND no convergence reached:  \n    1. Calculate new w using the gradient of the Log Loss  \n    2. Calculate new loss using my empirical loss function\n    3. Check if convergence has been reached  \n\n\n\n## Experiments:  \n\nIn my following experiments, I test both my regular and stochastic gradient descent algorithm using both linearly separable and non-linearly separable data. As you will see, this algorithm is powerful and has the ability to quickly classify linearly separable data with 100% accuracy. Additionally, as mentioned above, this algorithm is superior to Perceptron, as it can still converge on non-linearly separable data. Finally, you will see how batch size affects convergence with stochastic gradient descent. \n\n### Experiment 1: Fitting our Logistic Regression model on Linearly Seperable Data\n\n#### 1. Import relevant libraries\n\n#### 2. Make Linearly separable data\n\n#### 3. Fit our Logistic Regression model\n\n#### 4. Check our accuracy, weight vector, loss history\n\n#### Our model has 100% accuracy. Great! Now, let's visualize:  \n\n#### 5. Visualize\n\n### Experiment 2: Fitting our model on non-linear data:\n\n##### Unlike the Perceptron model, our LR model should still converge on non-linearly seperable data. Although the accuracy will not be 100%, we can still create a fairly accurate and dependable model.\n\n#### 1. Creating non-linearly separable data\n\n#### 2. Fitting our model\n\n#### 3. Similar to above, let's analyze our weight vecor, loss history, and accuracy\n\n#### Even though our data is not linearly separable, we still achieved 88% accuracy! Let's visualize:\n\n#### 4. Visualize:\n\n### Experiment 3: Choosing a learning rate that is too high:\n\n#### 1. Create data (let's choose linearly separable)\n\n#### 2. Fit our data. We will purposely choose a very high alpha to see how our model reacts\n\n#### 3. Let's check our loss, score, and history. We expect this high alpha value to negatively impact our model:\n\n#### However, we still achieve ~100% accuracy even with an alpha set at 20. Let's examine the gradient:\n\n#### Even though the gradient maintains the same shape as a lower alpha, there are noticeable bumps in the curve which show the effects of a higher alpha.\n\n### Experiment 4: Comparing Stochastic vs Regular gradient descent\n\nAs we can see, stochastic gradient descent, while slower, seems to produce a much better output than normal gradient descent. While normal gradient descent seems to eventually converge, stochastic gradient descent is far quicker in its convergence, which could be very important in machine learning applications.\n\n### Experiment 5: Batch size vs Convergence\n\n#### In this experiment, we want to see if batch size affects the model's convergent\n\n#### 1. Fit two models, one with a small batch size and another with a large batch size\n\n#### 2. Show convergence plots:\n\nAfter running this experiment multiple times, it is evident that a smaller batch size leads to a quicker convergence than a larger batch size. This result is not intuitive, as one might expect a larger batch size to be more accurate.\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"LR.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.189","title-block-banner":"../../img/landscape.png","title-block-banner-color":"white","theme":"cosmo","title":"Optimization with Gradient Descent","author":"Johnny Kantaros","date":"2023-03-04","image":"gradient.png","description":"Implementing Logistic Regression using Gradient Descent."},"extensions":{"book":{"multiFile":true}}}}}