{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Music Genre Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first download our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out a sample row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>release_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>len</th>\n",
       "      <th>dating</th>\n",
       "      <th>violence</th>\n",
       "      <th>world/life</th>\n",
       "      <th>...</th>\n",
       "      <th>sadness</th>\n",
       "      <th>feelings</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>energy</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mukesh</td>\n",
       "      <td>mohabbat bhi jhoothi</td>\n",
       "      <td>1950</td>\n",
       "      <td>pop</td>\n",
       "      <td>hold time feel break feel untrue convince spea...</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380299</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.357739</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.901822</td>\n",
       "      <td>0.339448</td>\n",
       "      <td>0.13711</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 artist_name            track_name  release_date genre  \\\n",
       "0           0      mukesh  mohabbat bhi jhoothi          1950   pop   \n",
       "\n",
       "                                              lyrics  len    dating  violence  \\\n",
       "0  hold time feel break feel untrue convince spea...   95  0.000598  0.063746   \n",
       "\n",
       "   world/life  ...   sadness  feelings  danceability  loudness  acousticness  \\\n",
       "0    0.000598  ...  0.380299  0.117175      0.357739  0.454119      0.997992   \n",
       "\n",
       "   instrumentalness   valence   energy    topic  age  \n",
       "0          0.901822  0.339448  0.13711  sadness  1.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the different genres represented and their associated frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "blues      4604\n",
       "country    5445\n",
       "hip hop     904\n",
       "jazz       3845\n",
       "pop        7042\n",
       "reggae     2498\n",
       "rock       4034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"genre\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure to encode each of these genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = {\n",
    "    \"blues\"     :  0,\n",
    "    \"country\"   :  1,\n",
    "    \"hip hop\"   :  2,\n",
    "    \"jazz\"      :  3,\n",
    "    \"pop\"       :  4,\n",
    "    \"reggae\"    :  5,\n",
    "    \"rock\"      :  6,\n",
    "}\n",
    "\n",
    "df = df[df[\"genre\"].apply(lambda x: x in genres.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genre\"] = df[\"genre\"].apply(genres.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can wrap our Pandas dataframe as a Torch dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataFromDF(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.df.iloc[index, 5], self.df.iloc[index, 4]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform a train/validation split and make datasets from each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_val = train_test_split(df,shuffle = True, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a training data set with two columns:  \n",
    "\n",
    "1. Lyrics\n",
    "2. Genre  \n",
    "\n",
    "Lets see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('somebody better shake somebody better turn head scratch like wild spit grind venom run gonna wild snakebite snakebite lover hide baby understand snakebite drag snakebite snakebite gonna gonna touch rebel skin break like matchstick baby kind mood face tattoo shoulder scratch bike yeah venom runnin gonna run scar right',\n",
       " 0)"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TextDataFromDF(df_train)\n",
    "val_data   = TextDataFromDF(df_val)\n",
    "train_data[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to build a vocabulary. First, we need to split each sentence into individual words. To do this, we will use a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Example\n",
    "tokenized = tokenizer(train_data[194][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will write a function to get tokens from the lyrics column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Make vocab\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=[\"<unk>\"], min_freq = 10)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word will have a unique mapping to an integer in the vocabulary. Here is the start of our vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'know',\n",
       " 'like',\n",
       " 'time',\n",
       " 'come',\n",
       " 'go',\n",
       " 'feel',\n",
       " 'away',\n",
       " 'heart',\n",
       " 'yeah']"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_itos()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Batch collation\n",
    "\n",
    "Here, we will develop the steps necessary to pass a batch of data to our training loop. Here are the steps:  \n",
    "\n",
    "1. Pull feature data (ex. batch of lyrics)\n",
    "2. Represent each lyrics as sequence of integers from vocab\n",
    "3. Pad the lyrics with unused integer index to keep length consistent\n",
    "4. Return the batch of lyrics as consolidated tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max length for lyrics\n",
    "max_len = 50\n",
    "\n",
    "# Count total number of tokens in vocab\n",
    "num_tokens = len(vocab.get_itos())\n",
    "\n",
    "# Make pipeline function\n",
    "def text_pipeline(x):\n",
    "\n",
    "    # First, we will make tokens for each word in lyrics\n",
    "    tokens = vocab(tokenizer(x))\n",
    "    \n",
    "    # Here, we will make a torch dataset with all 0's\n",
    "    # The length will be of size max_len\n",
    "    # We will add num_tokens to each value\n",
    "    y = torch.zeros(max_len, dtype=torch.int64) + num_tokens\n",
    "    \n",
    "    # If tokens > max tokens allowed, subset\n",
    "    if len(tokens) > max_len:\n",
    "        tokens = tokens[0:max_len]\n",
    "    \n",
    "    # Fix y to be the correct value for each token\n",
    "    # If there are not enough tokens, \n",
    "    # they will be represented by num_tokens\n",
    "    y[0:len(tokens)] = torch.tensor(tokens,dtype=torch.int64)\n",
    "    return y\n",
    "\n",
    "# Here, we write a simple function to convert \n",
    "# our label to integers instead of strings\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test our our function with simple lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1453, 2486,    0, 7529, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516,\n",
       "        8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516,\n",
       "        8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516,\n",
       "        8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516, 8516,\n",
       "        8516, 8516])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"Apple Banana Carrot Tomato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the first 4 words are found in the vocabulary and represented as their corresponding integers. The function sucessfully pads the remaining values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_text, _label) in batch:\n",
    "\n",
    "        # add label to list\n",
    "         label_list.append(label_pipeline(_label))\n",
    "\n",
    "         # add text (as sequence of integers) to list\n",
    "         processed_text = text_pipeline(_text)\n",
    "         text_list.append(processed_text)\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.stack(text_list)\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = DataLoader(val_data, batch_size=8, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets take a look at our batch of data now:  \n",
    "\n",
    "The first element is a list of the labels, and the second is the concatenated sequence of integers representing 8 song lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How do the embeddings work?\n",
    "2. Go over model - forward steps\n",
    "3. After we flatten, the tensor is 8x150, and the words leave their arrays - how does this make sense? Will they regain significance in the next loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size, embedding_dim, max_len, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size+1, embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc   = nn.Linear(max_len*embedding_dim, 50)\n",
    "        self.fc2   = nn.Linear(max_len*embedding_dim, num_class)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        # Insert mean\n",
    "        x = self.fc(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a word embedding to relate words together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 20\n",
    "model = TextClassificationModel(vocab_size, embedding_dim, max_len, 8).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run our model, lets find a base rate so we know if our model learns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base rate: 24.82%\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['genre'].value_counts()\n",
    "most_common_class = class_counts.idxmax()\n",
    "base_rate = (class_counts[most_common_class] / len(df)) * 100\n",
    "\n",
    "print(f\"Base rate: {base_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(dataloader):\n",
    "    epoch_start_time = time.time()\n",
    "    # keep track of some counts for measuring accuracy\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # form prediction on batch\n",
    "        predicted_label = model(text)\n",
    "        # evaluate loss on prediction\n",
    "        loss = loss_fn(predicted_label, label)\n",
    "        # compute gradient\n",
    "        loss.backward()\n",
    "        # take an optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "        # for printing accuracy\n",
    "        total_acc   += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        \n",
    "    print(f'| epoch {epoch:3d} | train accuracy {total_acc/total_count:8.3f} | time: {time.time() - epoch_start_time:5.2f}s')\n",
    "    # print('| end of epoch {:3d} | time: {:5.2f}s | '.format(epoch,\n",
    "    #                                        time.time() - epoch_start_time))\n",
    "    \n",
    "def evaluate(dataloader):\n",
    "\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TextClassificationModel                  [1, 50]                   8,008\n",
       "├─Embedding: 1-1                         [1, 50, 20]               170,340\n",
       "├─Dropout: 1-2                           [1, 50, 20]               --\n",
       "├─Linear: 1-3                            [1, 50]                   50,050\n",
       "==========================================================================================\n",
       "Total params: 228,398\n",
       "Trainable params: 228,398\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.22\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.88\n",
       "Estimated Total Size (MB): 0.89\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "INPUT_SHAPE = (1,max_len)\n",
    "summary(model, INPUT_SHAPE, dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | train accuracy    0.195 | time: 14.40s\n",
      "| epoch   2 | train accuracy    0.264 | time: 17.16s\n",
      "| epoch   3 | train accuracy    0.324 | time: 16.85s\n",
      "| epoch   4 | train accuracy    0.377 | time: 17.22s\n",
      "| epoch   5 | train accuracy    0.428 | time: 18.19s\n",
      "| epoch   6 | train accuracy    0.462 | time: 19.10s\n",
      "| epoch   7 | train accuracy    0.501 | time: 18.19s\n",
      "| epoch   8 | train accuracy    0.546 | time: 19.03s\n",
      "| epoch   9 | train accuracy    0.571 | time: 18.67s\n",
      "| epoch  10 | train accuracy    0.590 | time: 19.10s\n",
      "| epoch  11 | train accuracy    0.612 | time: 19.05s\n",
      "| epoch  12 | train accuracy    0.631 | time: 23.60s\n",
      "| epoch  13 | train accuracy    0.657 | time: 19.77s\n",
      "| epoch  14 | train accuracy    0.671 | time: 19.03s\n",
      "| epoch  15 | train accuracy    0.688 | time: 19.22s\n",
      "| epoch  16 | train accuracy    0.697 | time: 18.94s\n",
      "| epoch  17 | train accuracy    0.713 | time: 19.28s\n",
      "| epoch  18 | train accuracy    0.720 | time: 19.19s\n",
      "| epoch  19 | train accuracy    0.731 | time: 19.59s\n",
      "| epoch  20 | train accuracy    0.740 | time: 19.28s\n",
      "| epoch  21 | train accuracy    0.749 | time: 19.92s\n",
      "| epoch  22 | train accuracy    0.758 | time: 19.99s\n",
      "| epoch  23 | train accuracy    0.759 | time: 19.03s\n",
      "| epoch  24 | train accuracy    0.764 | time: 20.16s\n",
      "| epoch  25 | train accuracy    0.772 | time: 19.84s\n",
      "| epoch  26 | train accuracy    0.786 | time: 20.78s\n",
      "| epoch  27 | train accuracy    0.787 | time: 20.88s\n",
      "| epoch  28 | train accuracy    0.789 | time: 27.48s\n",
      "| epoch  29 | train accuracy    0.795 | time: 29.33s\n",
      "| epoch  30 | train accuracy    0.798 | time: 26.08s\n",
      "| epoch  31 | train accuracy    0.803 | time: 29.41s\n",
      "| epoch  32 | train accuracy    0.810 | time: 26.60s\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
